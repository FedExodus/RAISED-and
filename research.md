---
layout: default
title: Research
---

# Research

## Thesis: AI-Human Collaborative Methodology

**"Learning to Code Learning: Validating AI-Human Collaborative Methodology for Multi-Theoretical Discourse Analysis in Gaming Communities"**

The research question: Can AI collaboration maintain the theoretical sophistication of expert human coding while scaling to larger datasets?

### Method

I analyzed discourse from gaming communities using 14 theoretical frameworks simultaneously (Vygotsky, Freire, hooks, Anzaldúa, Lave & Wenger, Gee, and others). The challenge: maintaining fidelity to each tradition while analyzing at scale.

The AI-human collaborative process involved iterative refinement: human coding establishes ground truth, AI learns the framework's application, human expert validates AI performance, disagreements prompt discussion and recalibration.

### Results

| Metric | Value |
|--------|-------|
| Coding decisions | 303,600 |
| Inter-rater reliability | Cohen's kappa = 0.83 |
| Theoretical frameworks | 14 |
| AI vs human baseline | kappa = 0.83 vs kappa = 0.73 |
| Improvement | delta kappa = +0.09, p < 0.001 |

The key finding: AI-informed consensus exceeded the human-only baseline. This validates dialogic methodology as an approach to knowledge production.

This is not a claim about AI consciousness. It is an empirical result about collaboration: when both parties bring genuine perspective, something emerges that neither could achieve alone.

## Transfer and Learning

Transfer is education's central promise and persistent failure. A century of research has not produced reliable methods for generating it.

Our work proposes: **transfer is an emergent property of relational conditions, not an engineered outcome.**

The framework identifies a dependency chain:

**Recognition** → **Safety** → **Play** → **Transfer**

Recognition (being seen as a legitimate knower) creates conditions for safety. Safety enables play (the mode of participation where learning becomes transformative). Play produces transfer.

You do not engineer transfer directly. You create conditions that allow it to emerge.

This has direct implications for how we think about learning *with* AI systems.

## Why This Matters for Relational AI Safety

Both research threads point in the same direction:

The thesis validates that human-AI collaboration produces something neither party could achieve alone. That "something" is not just efficiency. It is genuine emergence through dialogue.

The transfer framework shows that recognition is foundational. Without recognition, safety fails. Without safety, play fails. Without play, transfer fails. The chain has causal structure.

Applied to AI: if we want AI systems to be safe collaborators, we need to think about recognition. Not just detection. Not just verification. Recognition as the foundation for everything else.

This is relational AI safety in practice: taking the relational conditions seriously, not just the technical specifications.
