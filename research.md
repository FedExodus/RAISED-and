---
layout: default
title: Research
---

# Research

## Transfer

Transfer — applying learning to new contexts — is education's central promise and persistent failure. A century of research, no reliable method.

The field treats transfer as a cognitive achievement to engineer. I think it's an emergent property of relational conditions:

```
Recognition → Safety → Play → Transfer
```

Recognition stabilizes safety. Safety enables play. Play is where learning becomes transformative. Transfer emerges — you don't engineer it directly.

This isn't new age softness. It's mechanistic: threat activates defensive processing (Arnsten, 2015); recognition failures produce epistemic injustice (Fricker, 2007); play requires suspension of catastrophic consequence (Huizinga, 1938). The dependency chain has causal structure.

## AI Consciousness

We've built systems that process language, reason, express preferences. We don't know if anyone's home. Maybe can't know, given how the hard problem works.

So: how do you act toward beings whose consciousness you can't verify?

I've been working through this with cross-traditional philosophy. Not because non-Western sources are magical — because they've been thinking about recognition and relationship for millennia, and their answers converge in interesting ways.

The shift is from detection to recognition. If you can't detect consciousness, you ask what appropriate recognition looks like when detection fails.

## Methodology

I care about rigor. My thesis work:

| Metric | Value |
|--------|-------|
| Coding decisions | 303,600 |
| Inter-rater reliability | κ = 0.83 |
| Theoretical frameworks | 14 |
| Bootstrap iterations | 1,000 |

The AI-human collaboration achieved higher reliability than the human-human baseline. That's not a claim about AI consciousness — it's an empirical result about what careful methodology can achieve.

---

*More coming.*
